{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fbc3090",
   "metadata": {},
   "source": [
    "# Retail Customer Purchase Prediction\n",
    "**COSC 4368 — Fundamentals of AI**\n",
    "\n",
    "Team: Matthew Nguyen, Benjamin Tran, Victor Bui, Gustavo Buenrostro  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c754eb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 1.7.2\n",
      "NB_DIR: c:\\Users\\mttng\\Downloads\\retail-customer-purchase-prediction\\notebook\n",
      "DATA_DIR: c:\\Users\\mttng\\Downloads\\retail-customer-purchase-prediction\\data\n",
      "Save figs → c:\\Users\\mttng\\Downloads\\retail-customer-purchase-prediction\\notebook\\outputs\\figures\\20251130-232438\n",
      "Save tables → c:\\Users\\mttng\\Downloads\\retail-customer-purchase-prediction\\notebook\\outputs\\tables\\20251130-232438\n"
     ]
    }
   ],
   "source": [
    "# 1) Reproducibility & environment\n",
    "import os, sys, json, time, math, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix,\n",
    "    roc_curve, auc, precision_recall_curve, classification_report, brier_score_loss,\n",
    "    average_precision_score, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# --- robust repo paths regardless of notebook location ---\n",
    "NB_DIR = Path.cwd()  # where this notebook is actually running\n",
    "DATA_DIR_CANDIDATES = [\n",
    "    NB_DIR / \"data\",        # ./data  (if notebook at repo root)\n",
    "    NB_DIR.parent / \"data\", # ../data (if notebook in ./notebook)\n",
    "    Path(\"/mnt/data\"),      # optional container path\n",
    "]\n",
    "for d in DATA_DIR_CANDIDATES:\n",
    "    if d.exists():\n",
    "        DATA_DIR = d\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"Couldn't locate a data/ folder. Checked:\\n  - \" +\n",
    "        \"\\n  - \".join(str(p) for p in DATA_DIR_CANDIDATES)\n",
    "    )\n",
    "\n",
    "# keep outputs under the notebook folder (matches your repo layout)\n",
    "OUT_FIG_BASE = NB_DIR / \"outputs\" / \"figures\"\n",
    "OUT_TAB_BASE = NB_DIR / \"outputs\" / \"tables\"\n",
    "OUT_FIG_BASE.mkdir(parents=True, exist_ok=True)\n",
    "OUT_TAB_BASE.mkdir(parents=True, exist_ok=True)\n",
    "RUN_STAMP = time.strftime('%Y%m%d-%H%M%S')\n",
    "OUT_FIG = OUT_FIG_BASE / RUN_STAMP; OUT_FIG.mkdir(parents=True, exist_ok=True)\n",
    "OUT_TAB = OUT_TAB_BASE / RUN_STAMP; OUT_TAB.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"sklearn:\", sklearn.__version__)\n",
    "print(\"NB_DIR:\", NB_DIR)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"Save figs →\", OUT_FIG)\n",
    "print(\"Save tables →\", OUT_TAB)\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "\n",
    "# 0) Global plot polish (slide-ready)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update({\n",
    "    \"figure.dpi\": 150,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"font.size\": 12,\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.25,\n",
    "})\n",
    "def add_threshold_marker(ax, thr, label=None, ymin=0, ymax=1):\n",
    "    ax.axvline(thr, linestyle=\"--\")\n",
    "    if label:\n",
    "        ax.text(thr, ymax, label, ha=\"right\", va=\"bottom\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a7d0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: c:\\Users\\mttng\\Downloads\\retail-customer-purchase-prediction\\data\\online_shoppers_intention.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>n_null</th>\n",
       "      <th>n_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Administrative</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>3335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BounceRates</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>1872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Browser</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExitRates</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>4777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Informational</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Informational_Duration</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OperatingSystems</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PageValues</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProductRelated</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>9551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Revenue</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpecialDay</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrafficType</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VisitorType</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weekend</th>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dtype  n_null  n_unique\n",
       "Administrative             int64       0        27\n",
       "Administrative_Duration  float64       0      3335\n",
       "BounceRates              float64       0      1872\n",
       "Browser                    int64       0        13\n",
       "ExitRates                float64       0      4777\n",
       "Informational              int64       0        17\n",
       "Informational_Duration   float64       0      1258\n",
       "Month                     object       0        10\n",
       "OperatingSystems           int64       0         8\n",
       "PageValues               float64       0      2704\n",
       "ProductRelated             int64       0       311\n",
       "ProductRelated_Duration  float64       0      9551\n",
       "Region                     int64       0         9\n",
       "Revenue                    int64       0         2\n",
       "SpecialDay               float64       0         6\n",
       "TrafficType                int64       0        20\n",
       "VisitorType               object       0         3\n",
       "Weekend                     bool       0         2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Load + Audit\n",
    "TARGET = \"Revenue\"\n",
    "candidates = [\n",
    "    DATA_DIR / \"online_shoppers_intention.csv\",\n",
    "    DATA_DIR / \"Online Shoppers Intention.csv\",  # alt name\n",
    "]\n",
    "for c in candidates:\n",
    "    if c.exists():\n",
    "        path = c\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(f\"online_shoppers_intention.csv not found in {DATA_DIR}\")\n",
    "\n",
    "print(\"Loading:\", path)\n",
    "df = pd.read_csv(path)\n",
    "if df[TARGET].dtype != int:\n",
    "    df[TARGET] = df[TARGET].astype(int)\n",
    "\n",
    "audit = pd.DataFrame({\n",
    "    \"dtype\": df.dtypes.astype(str),\n",
    "    \"n_null\": df.isnull().sum(),\n",
    "    \"n_unique\": df.nunique()\n",
    "}).sort_index()\n",
    "audit.to_csv(OUT_TAB / \"data_audit.csv\")\n",
    "audit.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe808b",
   "metadata": {},
   "source": [
    "# EDA & Leakage Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2ab945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage policy: only features known by session end; all transforms happen in Pipeline fit on TRAIN only.\n"
     ]
    }
   ],
   "source": [
    "# Class balance\n",
    "counts = df[TARGET].value_counts().sort_index()\n",
    "counts.to_csv(OUT_TAB / \"class_counts.csv\")\n",
    "ax = counts.plot(kind=\"bar\", title=\"Class Counts\")\n",
    "ax.figure.tight_layout(); ax.figure.savefig(OUT_FIG / \"class_counts.png\"); plt.close(ax.figure)\n",
    "\n",
    "# Helpful rates if present\n",
    "if \"Month\" in df.columns:\n",
    "    pr_month = df.groupby(\"Month\")[TARGET].mean().sort_values()\n",
    "    ax = pr_month.plot(kind=\"bar\", title=\"Purchase Rate by Month\")\n",
    "    ax.figure.tight_layout(); ax.figure.savefig(OUT_FIG / \"purchase_rate_by_month.png\"); plt.close(ax.figure)\n",
    "\n",
    "if \"VisitorType\" in df.columns:\n",
    "    pr_vtype = df.groupby(\"VisitorType\")[TARGET].mean().sort_values()\n",
    "    ax = pr_vtype.plot(kind=\"bar\", title=\"Purchase Rate by VisitorType\")\n",
    "    ax.figure.tight_layout(); ax.figure.savefig(OUT_FIG / \"purchase_rate_by_visitortype.png\"); plt.close(ax.figure)\n",
    "\n",
    "print(\"Leakage policy: only features known by session end; all transforms happen in Pipeline fit on TRAIN only.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ba6c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing & split\n",
    "NUM_COLS = df.drop(columns=[TARGET]).select_dtypes(include=[\"int64\",\"float64\",\"int32\",\"float32\"]).columns.tolist()\n",
    "CAT_COLS = [c for c in df.drop(columns=[TARGET]).columns if c not in NUM_COLS]\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), NUM_COLS),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_COLS)\n",
    "])\n",
    "\n",
    "X = df.drop(columns=[TARGET]); y = df[TARGET].astype(int)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, stratify=y, random_state=SEED)\n",
    "X_val, X_test, y_val, y_test   = train_test_split(X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=SEED)\n",
    "\n",
    "from collections import OrderedDict\n",
    "def fit_eval(pipe, name, Xtr=X_train, ytr=y_train, Xv=X_val, yv=y_val):\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    y_score = pipe.predict_proba(Xv)[:,1] if hasattr(pipe.named_steps[\"clf\"],\"predict_proba\") else pipe.decision_function(Xv)\n",
    "    y_pred  = (y_score >= 0.5).astype(int)\n",
    "    return pipe, OrderedDict(\n",
    "        model=name,\n",
    "        roc_auc_val=roc_auc_score(yv, y_score),\n",
    "        f1_val=f1_score(yv, y_pred),\n",
    "        precision_val=precision_score(yv, y_pred, zero_division=0),\n",
    "        recall_val=recall_score(yv, y_pred)\n",
    "    )\n",
    "\n",
    "val_rows = []; fitted = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685dce01",
   "metadata": {},
   "source": [
    "# Baselines (LR, DT) + quick visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3aec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr_pipe = Pipeline([(\"pre\", pre), (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=SEED))])\n",
    "lr_pipe, m = fit_eval(lr_pipe, \"LogisticRegression\")\n",
    "fitted[\"LogisticRegression\"] = lr_pipe; val_rows.append(m)\n",
    "\n",
    "# Decision Tree (small sweep)\n",
    "best_dt, best_m_dt = None, None\n",
    "for d in [3,5,10,None]:\n",
    "    dt = Pipeline([(\"pre\", pre), (\"clf\", DecisionTreeClassifier(max_depth=d, random_state=SEED))])\n",
    "    dt, mdict = fit_eval(dt, f\"DecisionTree(max_depth={d})\")\n",
    "    if best_m_dt is None or mdict[\"roc_auc_val\"] > best_m_dt[\"roc_auc_val\"]:\n",
    "        best_dt, best_m_dt = dt, mdict\n",
    "fitted[\"DecisionTree\"] = best_dt; val_rows.append(best_m_dt)\n",
    "\n",
    "val_df = pd.DataFrame(val_rows).sort_values(\"roc_auc_val\", ascending=False)\n",
    "val_df.to_csv(OUT_TAB / \"validation_metrics.csv\", index=False)\n",
    "val_df\n",
    "\n",
    "# Confusion matrix (validation) for LR\n",
    "pipe = fitted[\"LogisticRegression\"]\n",
    "ys = pipe.predict_proba(X_val)[:,1] if hasattr(pipe.named_steps[\"clf\"],\"predict_proba\") else pipe.decision_function(X_val)\n",
    "yp = (ys >= 0.5).astype(int)\n",
    "cm = confusion_matrix(y_val, yp)\n",
    "fig, ax = plt.subplots()\n",
    "ConfusionMatrixDisplay(cm, display_labels=[0,1]).plot(ax=ax, colorbar=False, values_format=\"d\")\n",
    "ax.set_title(\"Validation Confusion Matrix — LogisticRegression\")\n",
    "fig.tight_layout(); fig.savefig(OUT_FIG / \"confusion_matrix_val_logreg.png\"); plt.close(fig)\n",
    "\n",
    "# Top |coef| for LR\n",
    "pre_fit = pre.fit(X_train, y_train)\n",
    "try:  cat_names = list(pre_fit.named_transformers_[\"cat\"].get_feature_names_out(CAT_COLS))\n",
    "except: cat_names = [f\"{c}_{i}\" for i,c in enumerate(CAT_COLS)]\n",
    "feat_names = np.array(list(NUM_COLS) + cat_names)\n",
    "\n",
    "clf_lr = fitted[\"LogisticRegression\"].named_steps[\"clf\"]\n",
    "if hasattr(clf_lr,\"coef_\"):\n",
    "    coefs = np.ravel(clf_lr.coef_); order = np.argsort(np.abs(coefs))[::-1][:25]\n",
    "    fig, ax = plt.subplots(figsize=(6,8))\n",
    "    ax.barh(range(len(order)), np.abs(coefs[order])[::-1])\n",
    "    ax.set_yticks(range(len(order))); ax.set_yticklabels(feat_names[order][::-1])\n",
    "    ax.set_title(\"Top |Coefficient| — Logistic Regression\"); ax.set_xlabel(\"Absolute Weight\")\n",
    "    fig.tight_layout(); fig.savefig(OUT_FIG / \"lr_top_coefs.png\"); plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d2712",
   "metadata": {},
   "source": [
    "# Ensembles (RF & GB) + feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a174956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc_val</th>\n",
       "      <th>f1_val</th>\n",
       "      <th>precision_val</th>\n",
       "      <th>recall_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.920791</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>0.691304</td>\n",
       "      <td>0.555944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.914590</td>\n",
       "      <td>0.603696</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.513986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree(max_depth=5)</td>\n",
       "      <td>0.904419</td>\n",
       "      <td>0.576613</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.897592</td>\n",
       "      <td>0.599144</td>\n",
       "      <td>0.506024</td>\n",
       "      <td>0.734266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  roc_auc_val    f1_val  precision_val  recall_val\n",
       "3           GradientBoosting     0.920791  0.616279       0.691304    0.555944\n",
       "2               RandomForest     0.914590  0.603696       0.731343    0.513986\n",
       "1  DecisionTree(max_depth=5)     0.904419  0.576613       0.680952    0.500000\n",
       "0         LogisticRegression     0.897592  0.599144       0.506024    0.734266"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest (coarse CV)\n",
    "rf = RandomForestClassifier(random_state=SEED, n_estimators=300, n_jobs=-1)\n",
    "rf_pipe = Pipeline([(\"pre\", pre), (\"clf\", rf)])\n",
    "rf_cv = GridSearchCV(rf_pipe, {\"clf__max_depth\":[None,10,20], \"clf__min_samples_split\":[2,5,10]},\n",
    "                     scoring=\"roc_auc\", cv=5, n_jobs=-1)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "rf_best = rf_cv.best_estimator_\n",
    "ys = rf_best.predict_proba(X_val)[:,1] if hasattr(rf_best.named_steps[\"clf\"],\"predict_proba\") else rf_best.decision_function(X_val)\n",
    "yp = (ys >= 0.5).astype(int)\n",
    "val_rows.append(dict(model=\"RandomForest\",\n",
    "                     roc_auc_val=roc_auc_score(y_val, ys),\n",
    "                     f1_val=f1_score(y_val, yp),\n",
    "                     precision_val=precision_score(y_val, yp, zero_division=0),\n",
    "                     recall_val=recall_score(y_val, yp)))\n",
    "fitted[\"RandomForest\"] = rf_best\n",
    "\n",
    "# Feature importance (RF)\n",
    "clf = rf_best.named_steps[\"clf\"]\n",
    "if hasattr(clf, \"feature_importances_\"):\n",
    "    imps = np.asarray(clf.feature_importances_)\n",
    "    order = np.argsort(imps)[::-1][:20]\n",
    "    fig, ax = plt.subplots(figsize=(6,8))\n",
    "    ax.barh(range(len(order)), imps[order][::-1])\n",
    "    ax.set_yticks(range(len(order))); ax.set_yticklabels(feat_names[order][::-1])\n",
    "    ax.set_title(\"Top Feature Importance — Random Forest\"); ax.set_xlabel(\"Importance\")\n",
    "    fig.tight_layout(); fig.savefig(OUT_FIG / \"feature_importance_top20.png\"); plt.close(fig)\n",
    "    \n",
    "# Gradient Boosting (optional, keep if it wins)\n",
    "try:\n",
    "    gb = GradientBoostingClassifier(random_state=SEED)\n",
    "    gb_pipe = Pipeline([(\"pre\", pre), (\"clf\", gb)])\n",
    "    gb_cv = GridSearchCV(gb_pipe, {\"clf__learning_rate\":[0.05,0.1], \"clf__n_estimators\":[100,200], \"clf__max_depth\":[3]},\n",
    "                         scoring=\"roc_auc\", cv=5, n_jobs=-1)\n",
    "    gb_cv.fit(X_train, y_train)\n",
    "    gb_best = gb_cv.best_estimator_\n",
    "    ys = gb_best.predict_proba(X_val)[:,1] if hasattr(gb_best.named_steps[\"clf\"],\"predict_proba\") else gb_best.decision_function(X_val)\n",
    "    yp = (ys >= 0.5).astype(int)\n",
    "    val_rows.append(dict(model=\"GradientBoosting\",\n",
    "                         roc_auc_val=roc_auc_score(y_val, ys),\n",
    "                         f1_val=f1_score(y_val, yp),\n",
    "                         precision_val=precision_score(y_val, yp, zero_division=0),\n",
    "                         recall_val=recall_score(y_val, yp)))\n",
    "    fitted[\"GradientBoosting\"] = gb_best\n",
    "except Exception as e:\n",
    "    print(\"GB skipped:\", e)\n",
    "\n",
    "val_df = pd.DataFrame(val_rows).sort_values(\"roc_auc_val\", ascending=False)\n",
    "val_df.to_csv(OUT_TAB / \"validation_metrics.csv\", index=False)\n",
    "val_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b9c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP + learning curve with bands\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64,), activation=\"relu\", alpha=1e-4,\n",
    "                    early_stopping=True, random_state=SEED, max_iter=200)\n",
    "mlp_pipe = Pipeline([(\"pre\", pre), (\"clf\", mlp)])\n",
    "mlp_pipe, m = fit_eval(mlp_pipe, \"MLP(64)\")\n",
    "fitted[\"MLP\"] = mlp_pipe; val_rows.append(m)\n",
    "\n",
    "val_df = pd.DataFrame(val_rows).sort_values(\"roc_auc_val\", ascending=False)\n",
    "val_df.to_csv(OUT_TAB / \"validation_metrics.csv\", index=False)\n",
    "val_df\n",
    "\n",
    "# Learning curve (+/– bands)\n",
    "sizes, train_scores, val_scores = learning_curve(mlp_pipe, X_train, y_train, cv=5, scoring=\"roc_auc\",\n",
    "                                                 n_jobs=-1, train_sizes=np.linspace(0.2,1.0,5), shuffle=True, random_state=SEED)\n",
    "tr_m, tr_s = train_scores.mean(axis=1), train_scores.std(axis=1)\n",
    "va_m, va_s = val_scores.mean(axis=1), val_scores.std(axis=1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(sizes, tr_m, marker=\"o\", label=\"Train\"); ax.fill_between(sizes, tr_m-tr_s, tr_m+tr_s, alpha=0.2)\n",
    "ax.plot(sizes, va_m, marker=\"o\", label=\"CV\");    ax.fill_between(sizes, va_m-va_s, va_m+va_s, alpha=0.2)\n",
    "ax.set_title(\"Learning Curve — MLP\"); ax.set_xlabel(\"Train size\"); ax.set_ylabel(\"ROC-AUC\"); ax.legend(loc=\"best\")\n",
    "fig.tight_layout(); fig.savefig(OUT_FIG / \"mlp_learning_curve_bands.png\"); plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc497430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GradientBoosting', 0.325)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold sweep (validation) with chosen marker\n",
    "val_df = pd.DataFrame(val_rows).sort_values(\"roc_auc_val\", ascending=False)\n",
    "best_name = val_df.iloc[0][\"model\"]; best_pipe = fitted[best_name]\n",
    "y_score_val = best_pipe.predict_proba(X_val)[:,1] if hasattr(best_pipe.named_steps[\"clf\"],\"predict_proba\") else best_pipe.decision_function(X_val)\n",
    "\n",
    "ths = np.linspace(0.1, 0.9, 33); rows = []\n",
    "for t in ths:\n",
    "    pred = (y_score_val >= t).astype(int)\n",
    "    rows.append({\"threshold\": t, \"f1\": f1_score(y_val,pred),\n",
    "                 \"precision\": precision_score(y_val,pred,zero_division=0),\n",
    "                 \"recall\": recall_score(y_val,pred)})\n",
    "thr_df = pd.DataFrame(rows); thr_df.to_csv(OUT_TAB / \"threshold_sweep_val.csv\", index=False)\n",
    "best_thr = float(thr_df.sort_values(\"f1\", ascending=False).iloc[0][\"threshold\"])\n",
    "(Path(OUT_TAB / \"chosen_threshold.json\")).write_text(json.dumps({\"model\": best_name, \"threshold\": best_thr}, indent=2))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(thr_df[\"threshold\"], thr_df[\"precision\"], label=\"Precision\")\n",
    "ax.plot(thr_df[\"threshold\"], thr_df[\"recall\"], label=\"Recall\")\n",
    "ax.plot(thr_df[\"threshold\"], thr_df[\"f1\"], label=\"F1\")\n",
    "add_threshold_marker(ax, best_thr, f\"chosen t={best_thr:.3f}\", ymax=1.02)\n",
    "ax.set_xlabel(\"Threshold\"); ax.set_ylabel(\"Score\"); ax.set_title(f\"Threshold Sweep — {best_name} (Validation)\")\n",
    "ax.legend(loc=\"best\"); fig.tight_layout(); fig.savefig(OUT_FIG / \"threshold_sweep_marked.png\"); plt.close(fig)\n",
    "\n",
    "best_name, best_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aac22937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test evaluation (ROC, PR w/marker, Confusion %, Calibration/Brier)\n",
    "best_meta = json.loads((OUT_TAB / \"chosen_threshold.json\").read_text())\n",
    "best_name, best_thr = best_meta[\"model\"], best_meta[\"threshold\"]\n",
    "pipe = fitted[best_name]\n",
    "\n",
    "y_score_test = pipe.predict_proba(X_test)[:,1] if hasattr(pipe.named_steps[\"clf\"],\"predict_proba\") else pipe.decision_function(X_test)\n",
    "y_pred_test  = (y_score_test >= best_thr).astype(int)\n",
    "\n",
    "pd.DataFrame([{\n",
    "    \"model\": best_name, \"threshold\": best_thr,\n",
    "    \"roc_auc_test\": roc_auc_score(y_test, y_score_test),\n",
    "    \"f1_test\": f1_score(y_test, y_pred_test),\n",
    "    \"precision_test\": precision_score(y_test, y_pred_test, zero_division=0),\n",
    "    \"recall_test\": recall_score(y_test, y_pred_test)\n",
    "}]).to_csv(OUT_TAB / \"test_metrics.csv\", index=False)\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score_test)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr, label=f\"AUC={auc(fpr,tpr):.3f}\"); ax.plot([0,1],[0,1],\"--\")\n",
    "ax.set_title(f\"ROC Curve — Test ({best_name})\"); ax.set_xlabel(\"FPR\"); ax.set_ylabel(\"TPR\"); ax.legend(loc=\"lower right\")\n",
    "fig.tight_layout(); fig.savefig(OUT_FIG / \"roc_curve_test.png\"); plt.close(fig)\n",
    "\n",
    "# PR with chosen-threshold marker\n",
    "prec, rec, thr = precision_recall_curve(y_test, y_score_test); ap = average_precision_score(y_test, y_score_test)\n",
    "thr_idx = np.argmin(np.abs(thr - best_thr)) if len(thr)>0 else 0\n",
    "rec_at  = rec[thr_idx+1] if len(rec)>thr_idx+1 else rec[-1]\n",
    "prec_at = prec[thr_idx+1] if len(prec)>thr_idx+1 else prec[-1]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(rec, prec, label=f\"PR (AP={ap:.3f})\"); ax.scatter([rec_at], [prec_at])\n",
    "ax.set_title(\"Precision–Recall Curve — Test\"); ax.set_xlabel(\"Recall\"); ax.set_ylabel(\"Precision\"); ax.legend(loc=\"lower left\")\n",
    "fig.tight_layout(); fig.savefig(OUT_FIG / \"pr_curve_test_marked.png\"); plt.close(fig)\n",
    "\n",
    "# Confusion matrix with % overlay\n",
    "cm = confusion_matrix(y_test, y_pred_test); cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "fig, ax = plt.subplots()\n",
    "ConfusionMatrixDisplay(cm, display_labels=[0,1]).plot(ax=ax, colorbar=False, values_format=\"d\")\n",
    "ax.set_title(\"Confusion Matrix — Test\")\n",
    "for (i,j), v in np.ndenumerate(cm_norm):\n",
    "    ax.text(j, i, f\"\\n({v*100:.1f}%)\", ha=\"center\", va=\"top\")\n",
    "fig.tight_layout(); fig.savefig(OUT_FIG / \"confusion_matrix_test_pretty.png\"); plt.close(fig)\n",
    "\n",
    "# Calibration + Brier\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_score_test, n_bins=10, strategy=\"quantile\")\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(prob_pred, prob_true, marker=\"o\"); ax.plot([0,1],[0,1],\"--\")\n",
    "ax.set_title(\"Reliability (Calibration) — Test\"); ax.set_xlabel(\"Predicted probability\"); ax.set_ylabel(\"Observed frequency\")\n",
    "brier = brier_score_loss(y_test, y_score_test); ax.text(0.62, 0.08, f\"Brier={brier:.3f}\", transform=ax.transAxes)\n",
    "fig.tight_layout(); fig.savefig(OUT_FIG / \"calibration_curve_test_brier.png\"); plt.close(fig)\n",
    "(Path(OUT_TAB / \"brier_score.txt\")).write_text(str(brier))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c9e71c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretability (feature importances/coeffs)\n",
    "pre_fit = pre.fit(X_train, y_train)\n",
    "try:  cat_names = list(pre_fit.named_transformers_[\"cat\"].get_feature_names_out(CAT_COLS))\n",
    "except: cat_names = [f\"{c}_{i}\" for i,c in enumerate(CAT_COLS)]\n",
    "feat_names = np.array(list(NUM_COLS) + cat_names)\n",
    "\n",
    "clf = pipe.named_steps[\"clf\"]\n",
    "vals = np.asarray(clf.feature_importances_) if hasattr(clf,\"feature_importances_\") else (np.abs(np.ravel(clf.coef_)) if hasattr(clf,\"coef_\") else None)\n",
    "if vals is not None:\n",
    "    order = np.argsort(vals)[::-1][:25]\n",
    "    fig, ax = plt.subplots(figsize=(6,8))\n",
    "    ax.barh(range(len(order)), vals[order][::-1])\n",
    "    ax.set_yticks(range(len(order))); ax.set_yticklabels(feat_names[order][::-1])\n",
    "    ax.set_title(f\"Top Feature Signals — {best_name}\"); ax.set_xlabel(\"Importance / |Coefficient|\")\n",
    "    fig.tight_layout(); fig.savefig(OUT_FIG / \"feature_importance_top25.png\"); plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c90f0819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mttng\\AppData\\Local\\Temp\\ipykernel_1820\\2412642451.py:26: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  base = float(abl_df.loc[abl_df[\"group\"]==\"Full\",\"roc_auc_val\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>roc_auc_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Full</td>\n",
       "      <td>0.920791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BehavioralOnly</td>\n",
       "      <td>0.883948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TemporalTechOnly</td>\n",
       "      <td>0.703958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              group  roc_auc_val\n",
       "0              Full     0.920791\n",
       "1    BehavioralOnly     0.883948\n",
       "2  TemporalTechOnly     0.703958"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ablations (BehavioralOnly vs Temporal/TechOnly)\n",
    "BEHAVIORAL = [c for c in [\"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\n",
    "                          \"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\"] if c in X.columns]\n",
    "TEMPORAL_TECH = [c for c in [\"Month\",\"Weekend\",\"OperatingSystems\",\"Browser\",\"Region\",\"TrafficType\",\"VisitorType\"] if c in X.columns]\n",
    "\n",
    "def make_pre(cols_keep):\n",
    "    num = [c for c in cols_keep if c in NUM_COLS]\n",
    "    cat = [c for c in cols_keep if c in CAT_COLS]\n",
    "    return ColumnTransformer([(\"num\", StandardScaler(), num), (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat)])\n",
    "\n",
    "def eval_group(cols_keep, label):\n",
    "    from sklearn.base import clone\n",
    "    pre_g = make_pre(cols_keep)\n",
    "    # reuse the best family\n",
    "    base = fitted[best_name]\n",
    "    clf = clone(base.named_steps[\"clf\"])\n",
    "    pipe_g = Pipeline([(\"pre\", pre_g), (\"clf\", clf)])\n",
    "    _, m = fit_eval(pipe_g, f\"{best_name} | {label}\")\n",
    "    return m\n",
    "\n",
    "abl_rows = [{\"group\":\"Full\",\"roc_auc_val\": float(pd.DataFrame(val_rows).set_index(\"model\").loc[best_name,\"roc_auc_val\"])}]\n",
    "if BEHAVIORAL:    abl_rows.append({\"group\":\"BehavioralOnly\",   \"roc_auc_val\": eval_group(BEHAVIORAL, \"BehavioralOnly\")[\"roc_auc_val\"]})\n",
    "if TEMPORAL_TECH: abl_rows.append({\"group\":\"TemporalTechOnly\",\"roc_auc_val\": eval_group(TEMPORAL_TECH, \"TemporalTechOnly\")[\"roc_auc_val\"]})\n",
    "\n",
    "abl_df = pd.DataFrame(abl_rows); abl_df.to_csv(OUT_TAB / \"ablations.csv\", index=False)\n",
    "base = float(abl_df.loc[abl_df[\"group\"]==\"Full\",\"roc_auc_val\"])\n",
    "abl_df2 = abl_df.copy(); abl_df2[\"delta_auc\"] = abl_df2[\"roc_auc_val\"] - base\n",
    "ax = abl_df2.set_index(\"group\")[\"delta_auc\"].plot(kind=\"bar\", title=\"Ablation ΔAUC vs Full\")\n",
    "ax.figure.tight_layout(); ax.figure.savefig(OUT_FIG / \"ablation_delta_auc.png\"); plt.close(ax.figure)\n",
    "abl_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189af998",
   "metadata": {},
   "source": [
    "# Business visuals: cumulative gains, lift, per-1k; exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb3694c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export helper funcs\n",
    "def _save(fig, name):\n",
    "    p = OUT_FIG / f\"{name}.png\"\n",
    "    fig.savefig(p, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    return str(p)\n",
    "\n",
    "def export_all(model, X_test, y_test, feat_names, prefix=\"purchase_pred\", thr=None):\n",
    "    paths = {}\n",
    "    # ROC\n",
    "    y_score = model.predict_proba(X_test)[:,1] if hasattr(model.named_steps[\"clf\"],\"predict_proba\") else model.decision_function(X_test)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    fig, ax = plt.subplots(); ax.plot(fpr,tpr,label=f\"AUC={auc(fpr,tpr):.3f}\"); ax.plot([0,1],[0,1],\"--\")\n",
    "    ax.set_title(\"ROC Curve\"); ax.set_xlabel(\"FPR\"); ax.set_ylabel(\"TPR\"); ax.legend(loc=\"lower right\")\n",
    "    paths[\"roc\"] = _save(fig, f\"{prefix}_roc_test\")\n",
    "    # PR\n",
    "    prec, rec, thrv = precision_recall_curve(y_test, y_score); ap = average_precision_score(y_test, y_score)\n",
    "    fig, ax = plt.subplots(); ax.plot(rec, prec, label=f\"AP={ap:.3f}\")\n",
    "    if thr is not None and len(thrv)>0:\n",
    "        idx = np.argmin(np.abs(thrv - thr)); ax.scatter([rec[idx+1]],[prec[idx+1]])\n",
    "    ax.set_title(\"Precision–Recall Curve\"); ax.set_xlabel(\"Recall\"); ax.set_ylabel(\"Precision\"); ax.legend(loc=\"lower left\")\n",
    "    paths[\"pr\"] = _save(fig, f\"{prefix}_pr_test\")\n",
    "    # CM\n",
    "    y_pred = (y_score >= (thr if thr is not None else 0.5)).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(); ConfusionMatrixDisplay(cm, display_labels=[0,1]).plot(ax=ax, colorbar=False, values_format=\"d\")\n",
    "    ax.set_title(\"Confusion Matrix\"); paths[\"cm\"] = _save(fig, f\"{prefix}_cm_test\")\n",
    "    # Calibration\n",
    "    prob_true, prob_pred = calibration_curve(y_test, y_score, n_bins=10, strategy=\"quantile\")\n",
    "    fig, ax = plt.subplots(); ax.plot(prob_pred, prob_true, marker=\"o\"); ax.plot([0,1],[0,1],\"--\")\n",
    "    ax.set_title(\"Reliability (Calibration)\"); ax.set_xlabel(\"Predicted probability\"); ax.set_ylabel(\"Observed frequency\")\n",
    "    ax.text(0.6,0.1,f\"Brier={brier_score_loss(y_test, y_score):.3f}\", transform=ax.transAxes)\n",
    "    paths[\"cal\"] = _save(fig, f\"{prefix}_calibration_test\")\n",
    "    # Feature importance / coeffs\n",
    "    clf = model.named_steps[\"clf\"]\n",
    "    vals = np.asarray(clf.feature_importances_) if hasattr(clf,\"feature_importances_\") else (np.abs(np.ravel(clf.coef_)) if hasattr(clf,\"coef_\") else None)\n",
    "    if vals is not None:\n",
    "        order = np.argsort(vals)[::-1][:25]\n",
    "        fig, ax = plt.subplots(figsize=(6,8)); ax.barh(range(len(order)), vals[order][::-1])\n",
    "        ax.set_yticks(range(len(order))); ax.set_yticklabels(np.array(feat_names)[order][::-1])\n",
    "        ax.set_title(\"Top Signals\"); ax.set_xlabel(\"Importance / |Coefficient|\")\n",
    "        paths[\"feature_importance\"] = _save(fig, f\"{prefix}_feature_importance\")\n",
    "    (OUT_TAB / f\"{prefix}_classification_report.json\").write_text(\n",
    "        json.dumps(classification_report(y_test, y_pred, output_dict=True), indent=2),\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "    return paths\n",
    "\n",
    "# Names again\n",
    "pre_fit = pre.fit(X_train, y_train)\n",
    "try:\n",
    "    cat_names = list(pre_fit.named_transformers_[\"cat\"].get_feature_names_out(CAT_COLS))\n",
    "except:\n",
    "    cat_names = [f\"{c}_{i}\" for i,c in enumerate(CAT_COLS)]\n",
    "feat_names = list(NUM_COLS) + cat_names\n",
    "\n",
    "export_paths = export_all(pipe, X_test, y_test, feat_names, prefix=\"purchase_pred\", thr=best_thr)\n",
    "(OUT_TAB / \"export_paths.json\").write_text(\n",
    "    json.dumps(export_paths, indent=2, ensure_ascii=False),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "# Cumulative gains + lift\n",
    "order = np.argsort(-y_score_test); y_true_sorted = y_test.to_numpy()[order]\n",
    "cum_pos = np.cumsum(y_true_sorted); total_pos = y_true_sorted.sum()\n",
    "percent_samples = np.arange(1, len(y_true_sorted)+1) / len(y_true_sorted)\n",
    "gain = cum_pos / total_pos\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(percent_samples, gain, label=\"Model\"); ax.plot([0,1],[0,1], \"--\", label=\"Random\")\n",
    "ax.set_xlabel(\"Cumulative share of sessions\"); ax.set_ylabel(\"Cumulative share of buyers captured\")\n",
    "ax.set_title(\"Cumulative Gains — Test\"); ax.legend(loc=\"lower right\")\n",
    "fig.tight_layout(); fig.savefig(OUT_FIG / \"cumulative_gains.png\"); plt.close(fig)\n",
    "\n",
    "decile = max(1, int(0.1*len(y_true_sorted))); buyers_top10 = y_true_sorted[:decile].sum()\n",
    "lift_top10 = (buyers_top10 / decile) / y_test.mean()\n",
    "(OUT_TAB / \"lift_top10.txt\").write_text(\n",
    "    f\"Top-10% lift ≈ {lift_top10:.2f}×\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "# Per-1k sessions text\n",
    "alerts_rate = (y_pred_test == 1).mean()\n",
    "tp_rate = ((y_pred_test == 1) & (y_test == 1)).mean()\n",
    "(Path(OUT_TAB / \"per_1k.txt\")).write_text(\n",
    "    f\"Per 1,000 sessions → Alerts: {alerts_rate*1000:.0f}, True buyers captured: {tp_rate*1000:.0f}\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72693675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice error analysis (where FPs/FNs cluster) \n",
    "def slice_error_table(frame, y_true, y_pred, by):\n",
    "    df_ = pd.DataFrame({\"y\": y_true, \"yhat\": y_pred, by: frame[by]})\n",
    "    g = df_.groupby(by).agg(\n",
    "        n=(\"y\",\"size\"), pos=(\"y\",\"sum\"),\n",
    "        fp=(\"yhat\", lambda s: ((s==1) & (df_.loc[s.index,\"y\"]==0)).sum()),\n",
    "        fn=(\"yhat\", lambda s: ((s==0) & (df_.loc[s.index,\"y\"]==1)).sum()),\n",
    "    )\n",
    "    g[\"fp_rate\"] = g[\"fp\"] / g[\"n\"]; g[\"fn_rate\"] = g[\"fn\"] / g[\"n\"]\n",
    "    return g.sort_values(\"fp_rate\", ascending=False)\n",
    "\n",
    "slices = [c for c in [\"TrafficType\",\"Region\",\"Month\",\"VisitorType\"] if c in X_test.columns]\n",
    "for col in slices:\n",
    "    tab = slice_error_table(X_test, y_test.to_numpy(), y_pred_test, col)\n",
    "    tab.head(10).to_csv(OUT_TAB / f\"slice_errors_{col}.csv\")\n",
    "    top = tab.head(8)\n",
    "    fig, ax = plt.subplots(); ax.barh(top.index.astype(str), top[\"fp_rate\"]); ax.invert_yaxis()\n",
    "    ax.set_xlabel(\"False Positive Rate\"); ax.set_title(f\"Top FP Slices — {col}\")\n",
    "    fig.tight_layout(); fig.savefig(OUT_FIG / f\"slice_fp_{col}.png\"); plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "806ddf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.932790</td>\n",
       "      <td>0.007533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.930706</td>\n",
       "      <td>0.008746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.915896</td>\n",
       "      <td>0.007334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.911799</td>\n",
       "      <td>0.014636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.905606</td>\n",
       "      <td>0.010718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  auc_mean    auc_sd\n",
       "3    GradientBoosting  0.932790  0.007533\n",
       "2        RandomForest  0.930706  0.008746\n",
       "4                 MLP  0.915896  0.007334\n",
       "1        DecisionTree  0.911799  0.014636\n",
       "0  LogisticRegression  0.905606  0.010718"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV leaderboard with error bars\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "rows = []\n",
    "from sklearn.base import clone\n",
    "for mname, p in fitted.items():\n",
    "    scores = cross_val_score(clone(p), X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    rows.append({\"model\": mname, \"auc_mean\": scores.mean(), \"auc_sd\": scores.std()})\n",
    "cv_df = pd.DataFrame(rows).sort_values(\"auc_mean\", ascending=False)\n",
    "cv_df.to_csv(OUT_TAB / \"cv_leaderboard_auc.csv\", index=False)\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.barh(cv_df[\"model\"], cv_df[\"auc_mean\"], xerr=cv_df[\"auc_sd\"]); ax.invert_yaxis()\n",
    "ax.set_xlabel(\"ROC-AUC (mean ± sd, 5-fold)\"); ax.set_title(\"Validation Leaderboard (with variability)\")\n",
    "fig.tight_layout(); fig.savefig(OUT_FIG / \"cv_leaderboard_auc.png\"); plt.close(fig)\n",
    "cv_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20db6e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assets exported → C:\\Users\\mttng\\Downloads\\retail-customer-purchase-prediction\\presentations\\assets\n"
     ]
    }
   ],
   "source": [
    "# Bundle slide assets (ordered filenames)\n",
    "REPO_ROOT = NB_DIR if (NB_DIR / \"presentations\").exists() else (\n",
    "    NB_DIR.parent if (NB_DIR.parent / \"presentations\").exists() else NB_DIR\n",
    ")\n",
    "ASSET_DIR = REPO_ROOT / \"presentations\" / \"assets\"\n",
    "ASSET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ordered = [\n",
    "    \"class_counts.png\",\"cv_leaderboard_auc.png\",\"threshold_sweep_marked.png\",\"roc_curve_test.png\",\n",
    "    \"pr_curve_test_marked.png\",\"confusion_matrix_test_pretty.png\",\"calibration_curve_test_brier.png\",\n",
    "    \"feature_importance_top25.png\",\"mlp_learning_curve_bands.png\",\"cumulative_gains.png\",\"ablation_delta_auc.png\"\n",
    "]\n",
    "\n",
    "i = 1\n",
    "for name in ordered:\n",
    "    src = OUT_FIG / name\n",
    "    if src.exists():\n",
    "        (ASSET_DIR / f\"{i:02d}_{name}\").write_bytes(src.read_bytes())\n",
    "        i += 1\n",
    "\n",
    "print(\"Assets exported →\", ASSET_DIR.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
