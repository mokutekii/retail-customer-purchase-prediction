{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Retail Customer Purchase Prediction\n",
        "**COSC 4368 — Fundamentals of AI**\n",
        "\n",
        "Team: Matthew Nguyen, Benjamin Tran, Victor Bui, Gustavo Buenrostro  \n",
        "Date: (auto)\n",
        "\n",
        "## Abstract (fill after results)\n",
        "Brief problem, approach, and key result (ROC-AUC, F1).\n",
        "\n",
        "## Acknowledgments\n",
        "Instructor, peers; dataset: UCI Online Shoppers Intention (primary), UCI Online Retail II (optional RFM).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]\n",
            "pandas: 2.3.3\n",
            "numpy: 2.2.6\n",
            "sklearn: 1.7.2\n",
            "Save figs → C:\\Users\\mttng\\Downloads\\retail-customer-purchase-prediction\\outputs\\figures\\20251130-223010\n",
            "Save tables → C:\\Users\\mttng\\Downloads\\retail-customer-purchase-prediction\\outputs\\tables\\20251130-223010\n"
          ]
        }
      ],
      "source": [
        "# 1) Reproducibility & environment\n",
        "import os, sys, json, time, math, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix,\n",
        "    roc_curve, auc, precision_recall_curve, classification_report, brier_score_loss\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# project paths (repo root → this notebook under notebooks/)\n",
        "ROOT = Path().resolve().parents[0]  # Assumes notebook is in notebook/ subdirectory\n",
        "DATA_DIR = ROOT / \"data\"\n",
        "OUT_FIG_BASE = ROOT / \"outputs\" / \"figures\"\n",
        "OUT_TAB_BASE = ROOT / \"outputs\" / \"tables\"\n",
        "OUT_FIG_BASE.mkdir(parents=True, exist_ok=True)\n",
        "OUT_TAB_BASE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RUN_STAMP = time.strftime('%Y%m%d-%H%M%S')\n",
        "OUT_FIG = OUT_FIG_BASE / RUN_STAMP\n",
        "OUT_TAB = OUT_TAB_BASE / RUN_STAMP\n",
        "OUT_FIG.mkdir(parents=True, exist_ok=True)\n",
        "OUT_TAB.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"pandas:\", pd.__version__)\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"sklearn:\", sklearn.__version__)\n",
        "print(\"Save figs →\", OUT_FIG)\n",
        "print(\"Save tables →\", OUT_TAB)\n",
        "plt.rcParams[\"figure.dpi\"] = 150\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Data (primary) & feature plan\n",
        "Primary: UCI Online Shoppers (`Revenue` is the label).  \n",
        "Optional: Online Retail II → RFM enrichment later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((12330, 18),\n",
              "    Administrative  Administrative_Duration  Informational  \\\n",
              " 0               0                      0.0              0   \n",
              " 1               0                      0.0              0   \n",
              " 2               0                      0.0              0   \n",
              " 3               0                      0.0              0   \n",
              " 4               0                      0.0              0   \n",
              " \n",
              "    Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
              " 0                     0.0               1                 0.000000   \n",
              " 1                     0.0               2                64.000000   \n",
              " 2                     0.0               1                 0.000000   \n",
              " 3                     0.0               2                 2.666667   \n",
              " 4                     0.0              10               627.500000   \n",
              " \n",
              "    BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
              " 0         0.20       0.20         0.0         0.0   Feb                 1   \n",
              " 1         0.00       0.10         0.0         0.0   Feb                 2   \n",
              " 2         0.20       0.20         0.0         0.0   Feb                 4   \n",
              " 3         0.05       0.14         0.0         0.0   Feb                 3   \n",
              " 4         0.02       0.05         0.0         0.0   Feb                 3   \n",
              " \n",
              "    Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
              " 0        1       1            1  Returning_Visitor    False        0  \n",
              " 1        2       1            2  Returning_Visitor    False        0  \n",
              " 2        1       9            3  Returning_Visitor    False        0  \n",
              " 3        2       2            4  Returning_Visitor    False        0  \n",
              " 4        3       1            4  Returning_Visitor     True        0  )"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load primary dataset\n",
        "TARGET = \"Revenue\"\n",
        "df = pd.read_csv(DATA_DIR / \"online_shoppers_intention.csv\")\n",
        "if df[TARGET].dtype != int and df[TARGET].dtype != \"int64\":\n",
        "    df[TARGET] = df[TARGET].astype(int)\n",
        "df.shape, df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dtype</th>\n",
              "      <th>n_null</th>\n",
              "      <th>n_unique</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Administrative</th>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Administrative_Duration</th>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>3335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BounceRates</th>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>1872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Browser</th>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExitRates</th>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>4777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Informational</th>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Informational_Duration</th>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>1258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Month</th>\n",
              "      <td>object</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OperatingSystems</th>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PageValues</th>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>2704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ProductRelated</th>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ProductRelated_Duration</th>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>9551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Region</th>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Revenue</th>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SpecialDay</th>\n",
              "      <td>float64</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TrafficType</th>\n",
              "      <td>int64</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VisitorType</th>\n",
              "      <td>object</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weekend</th>\n",
              "      <td>bool</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           dtype  n_null  n_unique\n",
              "Administrative             int64       0        27\n",
              "Administrative_Duration  float64       0      3335\n",
              "BounceRates              float64       0      1872\n",
              "Browser                    int64       0        13\n",
              "ExitRates                float64       0      4777\n",
              "Informational              int64       0        17\n",
              "Informational_Duration   float64       0      1258\n",
              "Month                     object       0        10\n",
              "OperatingSystems           int64       0         8\n",
              "PageValues               float64       0      2704\n",
              "ProductRelated             int64       0       311\n",
              "ProductRelated_Duration  float64       0      9551\n",
              "Region                     int64       0         9\n",
              "Revenue                    int64       0         2\n",
              "SpecialDay               float64       0         6\n",
              "TrafficType                int64       0        20\n",
              "VisitorType               object       0         3\n",
              "Weekend                     bool       0         2"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Basic audit\n",
        "audit = pd.DataFrame({\n",
        "    \"dtype\": df.dtypes.astype(str),\n",
        "    \"n_null\": df.isnull().sum(),\n",
        "    \"n_unique\": df.nunique()\n",
        "}).sort_index()\n",
        "audit.to_csv(OUT_TAB / \"data_audit.csv\")\n",
        "audit.head(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Feature groups (plan)**\n",
        "- Behavioral: Administrative, Administrative_Duration, Informational, Informational_Duration,\n",
        "  ProductRelated, ProductRelated_Duration, BounceRates, ExitRates, PageValues, SpecialDay  \n",
        "- Temporal/Tech: Month, Weekend, OperatingSystems, Browser, Region, TrafficType, VisitorType  \n",
        "- RFM (optional extension)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) EDA & leakage audit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Revenue\n",
              " 0    10422\n",
              " 1     1908\n",
              " Name: count, dtype: int64,\n",
              " Revenue\n",
              " 0    0.845255\n",
              " 1    0.154745\n",
              " Name: proportion, dtype: float64)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Class balance\n",
        "counts = df[TARGET].value_counts().sort_index()\n",
        "counts.to_csv(OUT_TAB / \"class_counts.csv\")\n",
        "ax = counts.plot(kind=\"bar\", title=\"Class Counts\")\n",
        "fig = ax.get_figure(); fig.tight_layout(); fig.savefig(OUT_FIG / \"class_counts.png\"); plt.close(fig)\n",
        "counts, (counts / counts.sum()).rename(\"proportion\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Purchase rate by Month and VisitorType (if present)\n",
        "if \"Month\" in df.columns:\n",
        "    pr_month = df.groupby(\"Month\")[TARGET].mean().sort_values()\n",
        "    ax = pr_month.plot(kind=\"bar\", title=\"Purchase Rate by Month\")\n",
        "    fig = ax.get_figure(); fig.tight_layout(); fig.savefig(OUT_FIG / \"purchase_rate_by_month.png\"); plt.close(fig)\n",
        "\n",
        "if \"VisitorType\" in df.columns:\n",
        "    pr_vtype = df.groupby(\"VisitorType\")[TARGET].mean().sort_values()\n",
        "    ax = pr_vtype.plot(kind=\"bar\", title=\"Purchase Rate by VisitorType\")\n",
        "    fig = ax.get_figure(); fig.tight_layout(); fig.savefig(OUT_FIG / \"purchase_rate_by_visitortype.png\"); plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Leakage guardrails:** only use features known by session end; all transforms happen inside `Pipeline(pre, clf)` fit on **train only**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Preprocessing & split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8631, 1849, 1850)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Identify numeric and categorical columns\n",
        "NUM_COLS = df.drop(columns=[TARGET]).select_dtypes(include=[\"int64\",\"float64\",\"int32\",\"float32\"]).columns.tolist()\n",
        "CAT_COLS = [c for c in df.drop(columns=[TARGET]).columns if c not in NUM_COLS]\n",
        "\n",
        "pre = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), NUM_COLS),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_COLS)\n",
        "])\n",
        "\n",
        "# Split: 70/15/15 stratified\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET].astype(int)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, stratify=y, random_state=SEED\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=SEED\n",
        ")\n",
        "len(X_train), len(X_val), len(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# small utilities\n",
        "from collections import OrderedDict\n",
        "\n",
        "def fit_eval(pipe, name, Xtr=X_train, ytr=y_train, Xv=X_val, yv=y_val):\n",
        "    pipe.fit(Xtr, ytr)\n",
        "    if hasattr(pipe.named_steps[\"clf\"], \"predict_proba\"):\n",
        "        y_score = pipe.predict_proba(Xv)[:,1]\n",
        "    else:\n",
        "        y_score = pipe.decision_function(Xv)\n",
        "    y_pred = (y_score >= 0.5).astype(int)\n",
        "    met = OrderedDict(\n",
        "        model=name,\n",
        "        roc_auc_val=roc_auc_score(yv, y_score),\n",
        "        f1_val=f1_score(yv, y_pred),\n",
        "        precision_val=precision_score(yv, y_pred, zero_division=0),\n",
        "        recall_val=recall_score(yv, y_pred)\n",
        "    )\n",
        "    return pipe, met\n",
        "\n",
        "val_rows = []\n",
        "fitted = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Baselines (classical ML)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>roc_auc_val</th>\n",
              "      <th>f1_val</th>\n",
              "      <th>precision_val</th>\n",
              "      <th>recall_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.897592</td>\n",
              "      <td>0.599144</td>\n",
              "      <td>0.506024</td>\n",
              "      <td>0.734266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                model  roc_auc_val    f1_val  precision_val  recall_val\n",
              "0  LogisticRegression     0.897592  0.599144       0.506024    0.734266"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Logistic Regression (interpretable anchor)\n",
        "lr_pipe = Pipeline([(\"pre\", pre), (\"clf\", LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=SEED))])\n",
        "lr_pipe, m = fit_eval(lr_pipe, \"LogisticRegression\")\n",
        "fitted[\"LogisticRegression\"] = lr_pipe; val_rows.append(m)\n",
        "pd.DataFrame(val_rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>roc_auc_val</th>\n",
              "      <th>f1_val</th>\n",
              "      <th>precision_val</th>\n",
              "      <th>recall_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree(max_depth=5)</td>\n",
              "      <td>0.904419</td>\n",
              "      <td>0.576613</td>\n",
              "      <td>0.680952</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.897592</td>\n",
              "      <td>0.599144</td>\n",
              "      <td>0.506024</td>\n",
              "      <td>0.734266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       model  roc_auc_val    f1_val  precision_val  recall_val\n",
              "1  DecisionTree(max_depth=5)     0.904419  0.576613       0.680952    0.500000\n",
              "0         LogisticRegression     0.897592  0.599144       0.506024    0.734266"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Decision Tree (quick depth sweep)\n",
        "best_dt, best_m_dt = None, None\n",
        "for d in [3,5,10,None]:\n",
        "    dt = Pipeline([(\"pre\", pre), (\"clf\", DecisionTreeClassifier(max_depth=d, random_state=SEED))])\n",
        "    dt, mdict = fit_eval(dt, f\"DecisionTree(max_depth={d})\")\n",
        "    if best_m_dt is None or mdict[\"roc_auc_val\"] > best_m_dt[\"roc_auc_val\"]:\n",
        "        best_dt, best_m_dt = dt, mdict\n",
        "fitted[\"DecisionTree\"] = best_dt; val_rows.append(best_m_dt)\n",
        "val_df = pd.DataFrame(val_rows).sort_values(\"roc_auc_val\", ascending=False)\n",
        "val_df.to_csv(OUT_TAB / \"validation_metrics.csv\", index=False)\n",
        "val_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation confusion matrix for LR\n",
        "pipe = fitted[\"LogisticRegression\"]\n",
        "if hasattr(pipe.named_steps[\"clf\"], \"predict_proba\"):\n",
        "    y_score = pipe.predict_proba(X_val)[:,1]\n",
        "else:\n",
        "    y_score = pipe.decision_function(X_val)\n",
        "y_pred = (y_score >= 0.5).astype(int)\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "fig = plt.figure(); ax = fig.add_subplot(111)\n",
        "ax.imshow(cm, interpolation=\"nearest\")\n",
        "ax.set_title(\"Validation Confusion Matrix — LogisticRegression\")\n",
        "ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
        "for (i,j), v in np.ndenumerate(cm):\n",
        "    ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
        "fig.tight_layout(); fig.savefig(OUT_FIG / \"confusion_matrix_val_logreg.png\"); plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top LR coefficients (absolute) using feature names from fitted preprocessor\n",
        "pre_fit = pre.fit(X_train, y_train)\n",
        "try:\n",
        "    cat_names = list(pre_fit.named_transformers_[\"cat\"].get_feature_names_out(CAT_COLS))\n",
        "except Exception:\n",
        "    cat_names = [f\"{c}_{i}\" for i, c in enumerate(CAT_COLS)]\n",
        "feat_names = list(NUM_COLS) + cat_names\n",
        "\n",
        "clf = fitted[\"LogisticRegression\"].named_steps[\"clf\"]\n",
        "if hasattr(clf, \"coef_\"):\n",
        "    coefs = np.ravel(clf.coef_)\n",
        "    order = np.argsort(np.abs(coefs))[::-1][:25]\n",
        "    fig = plt.figure(figsize=(6,8)); ax = fig.add_subplot(111)\n",
        "    ax.barh(range(len(order)), np.abs(coefs[order])[::-1])\n",
        "    ax.set_yticks(range(len(order))); ax.set_yticklabels(np.array(feat_names)[order][::-1])\n",
        "    ax.set_title(\"Top |Coefficient| — Logistic Regression\"); ax.set_xlabel(\"Absolute Weight\")\n",
        "    fig.tight_layout(); fig.savefig(OUT_FIG / \"lr_top_coefs.png\"); plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Ensembles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>roc_auc_val</th>\n",
              "      <th>f1_val</th>\n",
              "      <th>precision_val</th>\n",
              "      <th>recall_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.914590</td>\n",
              "      <td>0.603696</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.513986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree(max_depth=5)</td>\n",
              "      <td>0.904419</td>\n",
              "      <td>0.576613</td>\n",
              "      <td>0.680952</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.897592</td>\n",
              "      <td>0.599144</td>\n",
              "      <td>0.506024</td>\n",
              "      <td>0.734266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       model  roc_auc_val    f1_val  precision_val  recall_val\n",
              "2               RandomForest     0.914590  0.603696       0.731343    0.513986\n",
              "1  DecisionTree(max_depth=5)     0.904419  0.576613       0.680952    0.500000\n",
              "0         LogisticRegression     0.897592  0.599144       0.506024    0.734266"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Random Forest (coarse CV grid)\n",
        "rf = RandomForestClassifier(random_state=SEED, n_estimators=300, n_jobs=-1)\n",
        "rf_pipe = Pipeline([(\"pre\", pre), (\"clf\", rf)])\n",
        "param_grid = {\n",
        "    \"clf__max_depth\": [None, 10, 20],\n",
        "    \"clf__min_samples_split\": [2, 5, 10]\n",
        "}\n",
        "rf_cv = GridSearchCV(rf_pipe, param_grid, scoring=\"roc_auc\", cv=5, n_jobs=-1)\n",
        "rf_cv.fit(X_train, y_train)\n",
        "rf_best = rf_cv.best_estimator_\n",
        "\n",
        "if hasattr(rf_best.named_steps[\"clf\"], \"predict_proba\"):\n",
        "    y_score = rf_best.predict_proba(X_val)[:,1]\n",
        "else:\n",
        "    y_score = rf_best.decision_function(X_val)\n",
        "y_pred = (y_score >= 0.5).astype(int)\n",
        "m = dict(model=\"RandomForest\", roc_auc_val=roc_auc_score(y_val, y_score),\n",
        "         f1_val=f1_score(y_val, y_pred), precision_val=precision_score(y_val, y_pred, zero_division=0),\n",
        "         recall_val=recall_score(y_val, y_pred))\n",
        "fitted[\"RandomForest\"] = rf_best; val_rows.append(m)\n",
        "\n",
        "# Feature importance\n",
        "clf = rf_best.named_steps[\"clf\"]\n",
        "if hasattr(clf, \"feature_importances_\"):\n",
        "    imps = np.asarray(clf.feature_importances_)\n",
        "    order = np.argsort(imps)[::-1][:20]\n",
        "    fig = plt.figure(figsize=(6,8)); ax = fig.add_subplot(111)\n",
        "    ax.barh(range(len(order)), imps[order][::-1])\n",
        "    ax.set_yticks(range(len(order))); ax.set_yticklabels(np.array(feat_names)[order][::-1])\n",
        "    ax.set_title(\"Top Feature Importance — Random Forest\"); ax.set_xlabel(\"Importance\")\n",
        "    fig.tight_layout(); fig.savefig(OUT_FIG / \"feature_importance_top20.png\"); plt.close(fig)\n",
        "\n",
        "val_df = pd.DataFrame(val_rows).sort_values(\"roc_auc_val\", ascending=False)\n",
        "val_df.to_csv(OUT_TAB / \"validation_metrics.csv\", index=False)\n",
        "val_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>roc_auc_val</th>\n",
              "      <th>f1_val</th>\n",
              "      <th>precision_val</th>\n",
              "      <th>recall_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GradientBoosting</td>\n",
              "      <td>0.920791</td>\n",
              "      <td>0.616279</td>\n",
              "      <td>0.691304</td>\n",
              "      <td>0.555944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.914590</td>\n",
              "      <td>0.603696</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.513986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree(max_depth=5)</td>\n",
              "      <td>0.904419</td>\n",
              "      <td>0.576613</td>\n",
              "      <td>0.680952</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.897592</td>\n",
              "      <td>0.599144</td>\n",
              "      <td>0.506024</td>\n",
              "      <td>0.734266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       model  roc_auc_val    f1_val  precision_val  recall_val\n",
              "3           GradientBoosting     0.920791  0.616279       0.691304    0.555944\n",
              "2               RandomForest     0.914590  0.603696       0.731343    0.513986\n",
              "1  DecisionTree(max_depth=5)     0.904419  0.576613       0.680952    0.500000\n",
              "0         LogisticRegression     0.897592  0.599144       0.506024    0.734266"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# (Optional) Gradient Boosting — enable if course allows\n",
        "try:\n",
        "    gb = GradientBoostingClassifier(random_state=SEED)\n",
        "    gb_pipe = Pipeline([(\"pre\", pre), (\"clf\", gb)])\n",
        "    gb_params = {\"clf__learning_rate\":[0.05,0.1], \"clf__n_estimators\":[100,200], \"clf__max_depth\":[3]}\n",
        "    gb_cv = GridSearchCV(gb_pipe, gb_params, scoring=\"roc_auc\", cv=5, n_jobs=-1)\n",
        "    gb_cv.fit(X_train, y_train)\n",
        "    gb_best = gb_cv.best_estimator_\n",
        "    if hasattr(gb_best.named_steps[\"clf\"], \"predict_proba\"):\n",
        "        y_score = gb_best.predict_proba(X_val)[:,1]\n",
        "    else:\n",
        "        y_score = gb_best.decision_function(X_val)\n",
        "    y_pred = (y_score >= 0.5).astype(int)\n",
        "    m = dict(model=\"GradientBoosting\", roc_auc_val=roc_auc_score(y_val, y_score),\n",
        "             f1_val=f1_score(y_val, y_pred), precision_val=precision_score(y_val, y_pred, zero_division=0),\n",
        "             recall_val=recall_score(y_val, y_pred))\n",
        "    fitted[\"GradientBoosting\"] = gb_best; val_rows.append(m)\n",
        "except Exception as e:\n",
        "    print(\"GradientBoosting skipped:\", e)\n",
        "\n",
        "val_df = pd.DataFrame(val_rows).sort_values(\"roc_auc_val\", ascending=False)\n",
        "val_df.to_csv(OUT_TAB / \"validation_metrics.csv\", index=False)\n",
        "val_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Neural network (shallow MLP)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>roc_auc_val</th>\n",
              "      <th>f1_val</th>\n",
              "      <th>precision_val</th>\n",
              "      <th>recall_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GradientBoosting</td>\n",
              "      <td>0.920791</td>\n",
              "      <td>0.616279</td>\n",
              "      <td>0.691304</td>\n",
              "      <td>0.555944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.914590</td>\n",
              "      <td>0.603696</td>\n",
              "      <td>0.731343</td>\n",
              "      <td>0.513986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MLP(64)</td>\n",
              "      <td>0.906668</td>\n",
              "      <td>0.599598</td>\n",
              "      <td>0.706161</td>\n",
              "      <td>0.520979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTree(max_depth=5)</td>\n",
              "      <td>0.904419</td>\n",
              "      <td>0.576613</td>\n",
              "      <td>0.680952</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.897592</td>\n",
              "      <td>0.599144</td>\n",
              "      <td>0.506024</td>\n",
              "      <td>0.734266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       model  roc_auc_val    f1_val  precision_val  recall_val\n",
              "3           GradientBoosting     0.920791  0.616279       0.691304    0.555944\n",
              "2               RandomForest     0.914590  0.603696       0.731343    0.513986\n",
              "4                    MLP(64)     0.906668  0.599598       0.706161    0.520979\n",
              "1  DecisionTree(max_depth=5)     0.904419  0.576613       0.680952    0.500000\n",
              "0         LogisticRegression     0.897592  0.599144       0.506024    0.734266"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(64,), activation=\"relu\", alpha=1e-4,\n",
        "                    early_stopping=True, random_state=SEED, max_iter=200)\n",
        "mlp_pipe = Pipeline([(\"pre\", pre), (\"clf\", mlp)])\n",
        "mlp_pipe, m = fit_eval(mlp_pipe, \"MLP(64)\")\n",
        "fitted[\"MLP\"] = mlp_pipe; val_rows.append(m)\n",
        "val_df = pd.DataFrame(val_rows).sort_values(\"roc_auc_val\", ascending=False)\n",
        "val_df.to_csv(OUT_TAB / \"validation_metrics.csv\", index=False)\n",
        "val_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Learning curve (5-fold CV) for MLP\n",
        "sizes, train_scores, val_scores = learning_curve(mlp_pipe, X_train, y_train, cv=5, scoring=\"roc_auc\",\n",
        "                                                 n_jobs=-1, train_sizes=np.linspace(0.2,1.0,5), shuffle=True, random_state=SEED)\n",
        "tr = train_scores.mean(axis=1); te = val_scores.mean(axis=1)\n",
        "fig = plt.figure(); ax = fig.add_subplot(111)\n",
        "ax.plot(sizes, tr, marker=\"o\", label=\"Train\")\n",
        "ax.plot(sizes, te, marker=\"o\", label=\"CV\")\n",
        "ax.set_title(\"Learning Curve — MLP\"); ax.set_xlabel(\"Train size\"); ax.set_ylabel(\"ROC-AUC\"); ax.legend(loc=\"best\")\n",
        "fig.tight_layout(); fig.savefig(OUT_FIG / \"mlp_learning_curve.png\"); plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('GradientBoosting', 0.325)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Pick best model by validation ROC-AUC\n",
        "val_df = pd.DataFrame(val_rows).sort_values(\"roc_auc_val\", ascending=False)\n",
        "best_name = val_df.iloc[0][\"model\"]\n",
        "best_pipe = fitted[best_name]\n",
        "\n",
        "# validation scores\n",
        "if hasattr(best_pipe.named_steps[\"clf\"], \"predict_proba\"):\n",
        "    y_score_val = best_pipe.predict_proba(X_val)[:,1]\n",
        "else:\n",
        "    y_score_val = best_pipe.decision_function(X_val)\n",
        "\n",
        "ths = np.linspace(0.1, 0.9, 33)\n",
        "rows = []\n",
        "for t in ths:\n",
        "    pred = (y_score_val >= t).astype(int)\n",
        "    rows.append({\n",
        "        \"threshold\": t,\n",
        "        \"f1\": f1_score(y_val, pred),\n",
        "        \"precision\": precision_score(y_val, pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_val, pred)\n",
        "    })\n",
        "thr_df = pd.DataFrame(rows)\n",
        "thr_df.to_csv(OUT_TAB / \"threshold_sweep_val.csv\", index=False)\n",
        "\n",
        "fig = plt.figure(); ax = fig.add_subplot(111)\n",
        "ax.plot(thr_df[\"threshold\"], thr_df[\"precision\"], label=\"Precision\")\n",
        "ax.plot(thr_df[\"threshold\"], thr_df[\"recall\"], label=\"Recall\")\n",
        "ax.plot(thr_df[\"threshold\"], thr_df[\"f1\"], label=\"F1\")\n",
        "ax.set_xlabel(\"Threshold\"); ax.set_ylabel(\"Score\")\n",
        "ax.set_title(f\"Threshold Sweep — {best_name} (Validation)\"); ax.legend(loc=\"best\")\n",
        "fig.tight_layout(); fig.savefig(OUT_FIG / \"threshold_sweep.png\"); plt.close(fig)\n",
        "\n",
        "best_thr = float(thr_df.sort_values(\"f1\", ascending=False).iloc[0][\"threshold\"])\n",
        "(Path(OUT_TAB / \"chosen_threshold.json\")).write_text(json.dumps({\"model\": best_name, \"threshold\": best_thr}, indent=2))\n",
        "best_name, best_thr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Test evaluation & calibration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'model': 'GradientBoosting', 'threshold': 0.325, 'roc_auc_test': 0.9330846583084434, 'f1_test': 0.6837060702875399, 'precision_test': 0.6294117647058823, 'recall_test': 0.7482517482517482}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_name = json.loads((OUT_TAB / \"chosen_threshold.json\").read_text())[\"model\"]\n",
        "best_thr = json.loads((OUT_TAB / \"chosen_threshold.json\").read_text())[\"threshold\"]\n",
        "pipe = fitted[best_name]\n",
        "\n",
        "# Scores\n",
        "if hasattr(pipe.named_steps[\"clf\"], \"predict_proba\"):\n",
        "    y_score_test = pipe.predict_proba(X_test)[:,1]\n",
        "else:\n",
        "    y_score_test = pipe.decision_function(X_test)\n",
        "\n",
        "y_pred_test = (y_score_test >= best_thr).astype(int)\n",
        "\n",
        "test_metrics = {\n",
        "    \"model\": best_name,\n",
        "    \"threshold\": best_thr,\n",
        "    \"roc_auc_test\": roc_auc_score(y_test, y_score_test),\n",
        "    \"f1_test\": f1_score(y_test, y_pred_test),\n",
        "    \"precision_test\": precision_score(y_test, y_pred_test, zero_division=0),\n",
        "    \"recall_test\": recall_score(y_test, y_pred_test)\n",
        "}\n",
        "pd.DataFrame([test_metrics]).to_csv(OUT_TAB / \"test_metrics.csv\", index=False)\n",
        "print(test_metrics)\n",
        "\n",
        "# ROC\n",
        "fpr, tpr, _ = roc_curve(y_test, y_score_test)\n",
        "fig = plt.figure(); ax = fig.add_subplot(111)\n",
        "ax.plot(fpr, tpr, label=f\"AUC={auc(fpr,tpr):.3f}\")\n",
        "ax.plot([0,1],[0,1],\"--\")\n",
        "ax.set_title(f\"ROC Curve — Test ({best_name})\"); ax.set_xlabel(\"FPR\"); ax.set_ylabel(\"TPR\"); ax.legend(loc=\"lower right\")\n",
        "fig.tight_layout(); fig.savefig(OUT_FIG / \"roc_curve_test.png\"); plt.close(fig)\n",
        "\n",
        "# PR\n",
        "prec, rec, _ = precision_recall_curve(y_test, y_score_test)\n",
        "fig = plt.figure(); ax = fig.add_subplot(111)\n",
        "ax.plot(rec, prec)\n",
        "ax.set_title(\"Precision–Recall Curve — Test\"); ax.set_xlabel(\"Recall\"); ax.set_ylabel(\"Precision\")\n",
        "fig.tight_layout(); fig.savefig(OUT_FIG / \"pr_curve_test.png\"); plt.close(fig)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "fig = plt.figure(); ax = fig.add_subplot(111)\n",
        "ax.imshow(cm, interpolation=\"nearest\")\n",
        "ax.set_title(\"Confusion Matrix — Test\"); ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
        "for (i,j), v in np.ndenumerate(cm):\n",
        "    ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
        "fig.tight_layout(); fig.savefig(OUT_FIG / \"confusion_matrix_test.png\"); plt.close(fig)\n",
        "\n",
        "# Calibration / Reliability & Brier\n",
        "prob_true, prob_pred = calibration_curve(y_test, y_score_test, n_bins=10, strategy=\"quantile\")\n",
        "fig = plt.figure(); ax = fig.add_subplot(111)\n",
        "ax.plot(prob_pred, prob_true, marker=\"o\"); ax.plot([0,1],[0,1],\"--\")\n",
        "ax.set_title(\"Reliability (Calibration) — Test\"); ax.set_xlabel(\"Predicted probability\"); ax.set_ylabel(\"Observed frequency\")\n",
        "brier = brier_score_loss(y_test, y_score_test); ax.text(0.6, 0.1, f\"Brier={brier:.3f}\", transform=ax.transAxes)\n",
        "fig.tight_layout(); fig.savefig(OUT_FIG / \"calibration_curve_test.png\"); plt.close(fig)\n",
        "(OUT_TAB / \"brier_score.txt\").write_text(str(brier))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Interpretability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Expanded feature names from fitted preprocessor\n",
        "pre_fit = pre.fit(X_train, y_train)\n",
        "try:\n",
        "    cat_names = list(pre_fit.named_transformers_[\"cat\"].get_feature_names_out(CAT_COLS))\n",
        "except Exception:\n",
        "    cat_names = [f\"{c}_{i}\" for i, c in enumerate(CAT_COLS)]\n",
        "feat_names = np.array(list(NUM_COLS) + cat_names)\n",
        "\n",
        "pipe = fitted[best_name]\n",
        "clf = pipe.named_steps[\"clf\"]\n",
        "vals = None; label = \"Importance\"\n",
        "if hasattr(clf, \"feature_importances_\"):\n",
        "    vals = np.asarray(clf.feature_importances_); label = \"Feature Importance\"\n",
        "elif hasattr(clf, \"coef_\"):\n",
        "    vals = np.abs(np.ravel(clf.coef_)); label = \"|Coefficient|\"\n",
        "\n",
        "if vals is not None:\n",
        "    order = np.argsort(vals)[::-1][:25]\n",
        "    fig = plt.figure(figsize=(6,8)); ax = fig.add_subplot(111)\n",
        "    ax.barh(range(len(order)), vals[order][::-1])\n",
        "    ax.set_yticks(range(len(order))); ax.set_yticklabels(feat_names[order][::-1])\n",
        "    ax.set_title(f\"Top {label} — {best_name}\"); ax.set_xlabel(label)\n",
        "    fig.tight_layout(); fig.savefig(OUT_FIG / \"feature_importance_top25.png\"); plt.close(fig)\n",
        "else:\n",
        "    print(\"Model does not expose feature importance or coefficients.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11) Ablations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\mttng\\AppData\\Local\\Temp\\ipykernel_26688\\2445940386.py:50: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  base = float(abl_df.loc[abl_df[\"group\"]==\"Full\",\"roc_auc_val\"])\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>roc_auc_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Full</td>\n",
              "      <td>0.920791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BehavioralOnly</td>\n",
              "      <td>0.882696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TemporalTechOnly</td>\n",
              "      <td>0.703532</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              group  roc_auc_val\n",
              "0              Full     0.920791\n",
              "1    BehavioralOnly     0.882696\n",
              "2  TemporalTechOnly     0.703532"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BEHAVIORAL = [c for c in [\n",
        "    \"Administrative\",\"Administrative_Duration\",\"Informational\",\"Informational_Duration\",\n",
        "    \"ProductRelated\",\"ProductRelated_Duration\",\"BounceRates\",\"ExitRates\",\"PageValues\",\"SpecialDay\"\n",
        "] if c in X.columns]\n",
        "\n",
        "TEMPORAL_TECH = [c for c in [\n",
        "    \"Month\",\"Weekend\",\"OperatingSystems\",\"Browser\",\"Region\",\"TrafficType\",\"VisitorType\"\n",
        "] if c in X.columns]\n",
        "\n",
        "def make_pre(cols_keep):\n",
        "    num = [c for c in cols_keep if c in NUM_COLS]\n",
        "    cat = [c for c in cols_keep if c in CAT_COLS]\n",
        "    return ColumnTransformer([(\"num\", StandardScaler(), num), (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat)])\n",
        "\n",
        "def eval_group(cols_keep, label):\n",
        "    pre_g = make_pre(cols_keep)\n",
        "    # reuse best model family for fairness\n",
        "    if best_name.startswith(\"RandomForest\"):\n",
        "        clf = RandomForestClassifier(random_state=SEED, n_estimators=300, n_jobs=-1)\n",
        "    elif best_name.startswith(\"GradientBoosting\") or best_name == \"GradientBoosting\":\n",
        "        clf = GradientBoostingClassifier(random_state=SEED)\n",
        "    elif best_name.startswith(\"MLP\") or best_name == \"MLP(64)\":\n",
        "        clf = MLPClassifier(hidden_layer_sizes=(64,), activation=\"relu\", alpha=1e-4, early_stopping=True, random_state=SEED, max_iter=200)\n",
        "    elif best_name.startswith(\"Logistic\") or best_name == \"LogisticRegression\":\n",
        "        clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=SEED)\n",
        "    else:\n",
        "        clf = RandomForestClassifier(random_state=SEED, n_estimators=300, n_jobs=-1)\n",
        "    pipe = Pipeline([(\"pre\", pre_g), (\"clf\", clf)])\n",
        "    _, m = fit_eval(pipe, f\"{best_name} | {label}\")\n",
        "    return m\n",
        "\n",
        "abl_rows = []\n",
        "# Full\n",
        "full_row = [r for r in val_rows if r[\"model\"]==best_name]\n",
        "if full_row:\n",
        "    abl_rows.append({\"group\":\"Full\", \"roc_auc_val\": full_row[0][\"roc_auc_val\"]})\n",
        "\n",
        "if BEHAVIORAL:\n",
        "    m = eval_group(BEHAVIORAL, \"BehavioralOnly\")\n",
        "    abl_rows.append({\"group\":\"BehavioralOnly\", \"roc_auc_val\": m[\"roc_auc_val\"]})\n",
        "\n",
        "if TEMPORAL_TECH:\n",
        "    m = eval_group(TEMPORAL_TECH, \"TemporalTechOnly\")\n",
        "    abl_rows.append({\"group\":\"TemporalTechOnly\", \"roc_auc_val\": m[\"roc_auc_val\"]})\n",
        "\n",
        "abl_df = pd.DataFrame(abl_rows)\n",
        "abl_df.to_csv(OUT_TAB / \"ablations.csv\", index=False)\n",
        "\n",
        "if \"Full\" in abl_df[\"group\"].values:\n",
        "    base = float(abl_df.loc[abl_df[\"group\"]==\"Full\",\"roc_auc_val\"])\n",
        "    abl_df2 = abl_df.copy()\n",
        "    abl_df2[\"delta_auc\"] = abl_df2[\"roc_auc_val\"] - base\n",
        "    ax = abl_df2.set_index(\"group\")[\"delta_auc\"].plot(kind=\"bar\", title=\"Ablation ΔAUC vs Full\")\n",
        "    fig = ax.get_figure(); fig.tight_layout(); fig.savefig(OUT_FIG / \"ablation_delta_auc.png\"); plt.close(fig)\n",
        "abl_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12) Business takeaways (fill 5–7 bullets)\n",
        "- Signals that most increase purchase likelihood  \n",
        "- Recommended operating threshold and trade-offs  \n",
        "- Implications for remarketing and UX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13) Conclusion & future direction\n",
        "- Best model and trade-offs  \n",
        "- Future: calibration tuning, cost-sensitive metrics, RFM enrichment, deployment hooks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14) Optional RFM (Online Retail II)\n",
        "Hook for building Recency, Frequency, Monetary features and joining if a key exists.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assets exported → C:\\Users\\mttng\\Downloads\\retail-customer-purchase-prediction\\presentations\\assets\n"
          ]
        }
      ],
      "source": [
        "# 15) Export helpers & final assets\n",
        "def _save(fig, name):\n",
        "    path = (OUT_FIG / f\"{name}.png\")\n",
        "    fig.savefig(path, dpi=300, bbox_inches=\"tight\"); plt.close(fig); return str(path)\n",
        "\n",
        "def save_confusion_matrix(model, X, y, name):\n",
        "    y_hat = model.predict(X)\n",
        "    cm = confusion_matrix(y, y_hat)\n",
        "    fig = plt.figure(); ax = fig.add_subplot(111)\n",
        "    ax.imshow(cm, interpolation=\"nearest\"); ax.set_title(\"Confusion Matrix\")\n",
        "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
        "    for (i,j), v in np.ndenumerate(cm): ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
        "    return _save(fig, name)\n",
        "\n",
        "def save_roc(model, X, y, name):\n",
        "    if hasattr(model.named_steps[\"clf\"], \"predict_proba\"): y_score = model.predict_proba(X)[:,1]\n",
        "    else: y_score = model.decision_function(X)\n",
        "    fpr, tpr, _ = roc_curve(y, y_score)\n",
        "    fig = plt.figure(); ax = fig.add_subplot(111)\n",
        "    ax.plot(fpr, tpr, label=f\"AUC={auc(fpr,tpr):.3f}\"); ax.plot([0,1],[0,1],\"--\")\n",
        "    ax.set_title(\"ROC Curve\"); ax.set_xlabel(\"FPR\"); ax.set_ylabel(\"TPR\"); ax.legend(loc=\"lower right\")\n",
        "    return _save(fig, name)\n",
        "\n",
        "def save_pr(model, X, y, name):\n",
        "    if hasattr(model.named_steps[\"clf\"], \"predict_proba\"): y_score = model.predict_proba(X)[:,1]\n",
        "    else: y_score = model.decision_function(X)\n",
        "    precision, recall, _ = precision_recall_curve(y, y_score)\n",
        "    fig = plt.figure(); ax = fig.add_subplot(111)\n",
        "    ax.plot(recall, precision); ax.set_title(\"Precision–Recall Curve\"); ax.set_xlabel(\"Recall\"); ax.set_ylabel(\"Precision\")\n",
        "    return _save(fig, name)\n",
        "\n",
        "def save_calibration(model, X, y, name):\n",
        "    if hasattr(model.named_steps[\"clf\"], \"predict_proba\"): y_score = model.predict_proba(X)[:,1]\n",
        "    else:\n",
        "        y_score = model.decision_function(X)\n",
        "        y_score = (y_score - y_score.min()) / (y_score.max() - y_score.min() + 1e-12)\n",
        "    prob_true, prob_pred = calibration_curve(y, y_score, n_bins=10, strategy=\"quantile\")\n",
        "    fig = plt.figure(); ax = fig.add_subplot(111)\n",
        "    ax.plot(prob_pred, prob_true, marker=\"o\"); ax.plot([0,1],[0,1],\"--\")\n",
        "    ax.set_title(\"Reliability (Calibration)\"); ax.set_xlabel(\"Predicted probability\"); ax.set_ylabel(\"Observed frequency\")\n",
        "    brier = brier_score_loss(y, y_score); ax.text(0.6, 0.1, f\"Brier={brier:.3f}\", transform=ax.transAxes)\n",
        "    return _save(fig, name)\n",
        "\n",
        "def save_feature_importance_fig(model, feat_names, name):\n",
        "    clf = model.named_steps[\"clf\"]\n",
        "    vals = None; label=\"Importance\"\n",
        "    if hasattr(clf, \"feature_importances_\"):\n",
        "        vals = np.asarray(clf.feature_importances_); label=\"Feature Importance\"\n",
        "    elif hasattr(clf, \"coef_\"):\n",
        "        vals = np.abs(np.ravel(clf.coef_)); label=\"|Coefficient|\"\n",
        "    if vals is None: return None\n",
        "    order = np.argsort(vals)[::-1][:25]\n",
        "    fig = plt.figure(figsize=(6,8)); ax = fig.add_subplot(111)\n",
        "    ax.barh(range(len(order)), vals[order][::-1])\n",
        "    ax.set_yticks(range(len(order))); ax.set_yticklabels(np.array(feat_names)[order][::-1])\n",
        "    ax.set_title(f\"Top {label}\"); ax.set_xlabel(label)\n",
        "    return _save(fig, name)\n",
        "\n",
        "def export_all(model, X_test, y_test, feat_names, prefix=\"purchase_pred\"):\n",
        "    paths = {}\n",
        "    paths[\"roc\"] = save_roc(model, X_test, y_test, f\"{prefix}_roc_test\")\n",
        "    paths[\"pr\"] = save_pr(model, X_test, y_test, f\"{prefix}_pr_test\")\n",
        "    paths[\"cm\"] = save_confusion_matrix(model, X_test, y_test, f\"{prefix}_cm_test\")\n",
        "    paths[\"cal\"] = save_calibration(model, X_test, y_test, f\"{prefix}_calibration_test\")\n",
        "    fi = save_feature_importance_fig(model, feat_names, f\"{prefix}_feature_importance\")\n",
        "    if fi: paths[\"feature_importance\"] = fi\n",
        "    rep = classification_report(y_test, model.predict(X_test), output_dict=True)\n",
        "    (OUT_TAB / f\"{prefix}_classification_report.json\").write_text(json.dumps(rep, indent=2))\n",
        "    return paths\n",
        "\n",
        "# Expanded names for feature-importance figure\n",
        "pre_fit = pre.fit(X_train, y_train)\n",
        "try:\n",
        "    cat_names = list(pre_fit.named_transformers_[\"cat\"].get_feature_names_out(CAT_COLS))\n",
        "except Exception:\n",
        "    cat_names = [f\"{c}_{i}\" for i, c in enumerate(CAT_COLS)]\n",
        "feat_names = list(NUM_COLS) + cat_names\n",
        "\n",
        "export_paths = export_all(fitted[best_name], X_test, y_test, feat_names, prefix=\"purchase_pred\")\n",
        "(OUT_TAB / \"export_paths.json\").write_text(json.dumps(export_paths, indent=2, ensure_ascii=False))\n",
        "\n",
        "# Collect a curated set for slides/poster\n",
        "ASSET_DIR = ROOT / \"presentations\" / \"assets\"\n",
        "ASSET_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ordered = [\"class_counts.png\",\"threshold_sweep.png\",\"roc_curve_test.png\",\"confusion_matrix_test.png\",\n",
        "           \"feature_importance_top20.png\",\"feature_importance_top25.png\",\"mlp_learning_curve.png\",\"ablation_delta_auc.png\"]\n",
        "i = 1\n",
        "for name in ordered:\n",
        "    src = OUT_FIG / name\n",
        "    if src.exists():\n",
        "        (ASSET_DIR / f\"{i:02d}_{name}\").write_bytes(src.read_bytes()); i += 1\n",
        "print(\"Assets exported →\", ASSET_DIR)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
